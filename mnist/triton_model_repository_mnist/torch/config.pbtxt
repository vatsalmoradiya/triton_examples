name: "torch"
platform: "pytorch_libtorch"
dynamic_batching { 
preferred_batch_size: [164,128,256]
max_queue_delay_microseconds: 100
}

max_batch_size: 1024
input {
    name: "input__0"
    format: FORMAT_NCHW
    data_type: TYPE_FP32
    dims: [1,28,28]
}

output {
    name: "output__0"
    data_type: TYPE_FP32
    dims: [10]
}

instance_group [
    {
        count: 1
        kind: KIND_GPU
        gpus: [0]
    }
]

default_model_filename: "model.pt"
